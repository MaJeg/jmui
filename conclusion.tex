\section{Conclusion}

\subsection{Contribution of this article}

We presented three different contributions in this article. First, we elaborated a theoretical model for the coordination of turn between the user and the agent. Our assumption in this model is that the coordination of turn is partly an emergent property that comes from the sensorimotor coupling between the participants. We simulated the model in the context of theoretical agent-agent simulation. We showed in this context the capacity of agents controlled by our model to coordinate and reproduce qualitatively the situations observed in human interactions. The agents controlled by our theoretical model are adaptative, they are able to ensure a coordination in different types of environment and in interactions with partners that have more or less inertia in producing their signals or perceive more or less rapidly the behavior of their partner. Even if we presented only two types of adaptation, to the absence of presence of signals and to the way the user produces its signals. These simulations shows the capability of an emergent model to reproduce the situations linked to the coordination of turns observed in human conversations.

This adaptative capability is essential as their exist a variability in the way the users coordinate their turns with the agent. This adaptation mecanism is based on the idea that the participants modify the way they produce their signals in order to keep an effective coordination of turns between participats. This principle is interesting because it highlight the fact that, not only the agent must be able to perceive reliably the user's intentions, but the latter has also to perceive reliably the behavior of the agent in different environmnental settings. One way to guaranty that the user still  perceive reliably the behavior of the agent is that the agent adapt its behavior to clarify its intentions to the user, capacity that we observed in our theoretical simulations without needing to modify the signal control equations of the agent. This view of user-agent adaptation is also new in the context of user-agent turn-taking as past approaches relied on offline machine learning techniques or online reinforcement learning to perceive reliably the behavior of the user, without taking into account the way the user perceives the agent behavior. 
However, aplying this principle of adaptation requires also the ability of the user to adapt the production of its signals in order to clarify its behavior and intentions. Whether the user could adapt its behavior to the agent and environment is currently a research questions, a need further analysis of user-agent interactions to answer this question. Some clues let us think that a kind of adaptation of the user to the agent is done, as we observed a variability in the silence duration after the end of the agent's turn and before the user's beginning of turn whether the user interacted with the agent controlled by our model or interacted with the agent controlled by a model based on temporal thresholds. Nevertheless, we do not know the exact reason of this variability, it could be due to the prosodic signals produced by the agent at the end of its turn or linked to an temporal alignment of the user to the way the agent takes the turn, a phenomenon that is observed in conversations. 

As a second contribution, we presented an architecture for the implementation of both continuous and discrete control models of the agent's behavior. Our model distinguish from traditional evenemential, purely reactive models and rather is based on a continuous perception of the user's behavioral cues and a continuous modulation of the agent's actions. Few actual embodied conversational agents permit to implement these types of models. In order to integrate our model in a embodied conversational agent architecture we extended the actual ASAP architecture \cite{kopp_architecture_2014} with different principles inspired from the Ymir architecture \citep{thorisson_mind_1999}. By extending ASAP compliant with the current SAIBA standard, we made our model integrable with existing modules, managing other aspects of user-agent interactions, such as verbal interaction, emotions or interpersonal attitudes or realizers managing gestures or the gaze direction of the agent. As a demonstration, we showed the capability of an agent controlled by our model to manage turns in real-time dialogical interactions with users, and showed that in some ways, our model work with real-time user-agent behaviors. 

Finally, we analyzed real-time interactions between user and agent. Our aim was to complement actual perceptual studies about the user's experience with an agent modulating its turns, and verifying the effectiveness of the coordination between several interactions with different users. We then measured factors related to the credibility of the agent, its social presence, the satisfaction and easiness the user interacted with the agent.  We did not observe differences in the answers of the participants to the questions about those factors. We also found that participant did not always perceived the interruption of the agent as voluntary, and we found that the agent had troubles sometimes coordinating with the user. Different elements can be improved to improve the interaction between the user and the agent. First, the unvolontary and voluntary aspect of the interruptions are likely to be linked with the verbal content of the agent's utterance, and maybe there need to be a particular way to formulate the utterance when interrupting the user. It would then necessitates an extension of our actual model, linked to the management of the verbal content linked to turn-taking. Second, the agent only interacts with the user by interpreting and modulating prosody, adding multimodal interpretation abilities could certainly improve the way the agent coordinates with the user. Also for this implementation, since we determined manually the parameters of the agent's equations, optimizing these parameters could improve the coordination between the user and the agent. 

\subsection{Future work}

In the future, we plan to explore more in details the different mecanism of alignment linked to the coordination of turns as highlighted by authors \citep{benus_pragmatic_2011}, we wish to show that our current model could account for the temporal alignment we can observe in human conversations.  
As we mentioned in section \ref{backgd}, a complete turn-taking model makes intervene several cognitive process, from sensorimotor coupling to projection, and in order to have a complete turn-taking model, we need to take into account all these processes. One of the major question regarding these process in how verbal content interpretation should be done by an agent. To adress this question, \cite{de_vault_incremental_2011} proposed a statistical model where the following sentence and the content is predicted by the agent. This method could work in real-time interactions when the agent the dialog domain is well determined but as the dialog capacities and the set of utterance the user could say increases this method could become rapdily fastidious or even impossible to perform by an agent. 
As mentionned in section \ref{backgd}, verbal content is however one of the mostly used signals for the listener to detect end of turn \cite{de_ruiter_projecting_2006}, and should considerably help participants to coordinate the speaking turns. Nevertheless, the way we could implement the interpretation mecanism in an embodied conversational agents remains unclear, firstly because the process used by human participants to coordinate turns based on verbal informations is still debated \citep{heldner_pauses_2010,magyari_prediction_2012,riest_anticipation_2015}. Secondly, because the way hypothesized by a majority of authors implies perceiving reliably word by word the utterance said by the user and be able to perceive and reason about the syntax of the utterance in real-time \citep{sacks_simplest_1974}, capacities that current natural language understanding components barely have currently. 
Other extension possibility is linked to the management of speaking turns in multiparty interactions. Such models makes intervene other issues like addressing its utterance to one or a subset of participants and for as listener detecting the role its has in conversations (addressee, bystander, overhearer), managing conflicts between several previous listeners trying to take the turn at the same time. These issues are linked to a more complex management of gaze direction, the management of the participants locations. 
Moreover, our model makes intervene a motivation to change role and a motivation to keep role. Usually in human conversation, when participants are motivated to be and stay listeners, they produce backchannel in order to show the current speaker they still listen what he is saying. Thus, in our model, we could exploit this motivation to keep the agent's role to implement some behaviors related to grounding such as backchannels. For the speaker, interpreting a backchannel at some moments in time could impact the perception of the user's behavior related to turn-taking as a user producing backchannel likely won't change role immediately.

% 